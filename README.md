# Apache Airflow 3.1.3 å®‰è£…æˆåŠŸï¼

## ğŸ‰ å®‰è£…å®Œæˆ

æ­å–œï¼æ‚¨å·²ç»æˆåŠŸå®‰è£…äº†æœ€æ–°ç‰ˆæœ¬çš„ Apache Airflow (3.1.3)ã€‚

## ğŸ“‹ ç™»å½•ä¿¡æ¯

- **Web UI åœ°å€**: http://localhost:8080
- **ç”¨æˆ·å**: `airflow`
- **å¯†ç **: `airflow`

## ğŸš€ å¿«é€Ÿå¼€å§‹

### è®¿é—® Airflow Web ç•Œé¢

åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:8080ï¼Œä½¿ç”¨ä¸Šé¢çš„ç”¨æˆ·åå’Œå¯†ç ç™»å½•ã€‚

### ç®¡ç† Airflow æœåŠ¡

#### å¯åŠ¨æ‰€æœ‰æœåŠ¡

```powershell
docker compose up -d
```

#### åœæ­¢æ‰€æœ‰æœåŠ¡

```powershell
docker compose down
```

#### æŸ¥çœ‹æœåŠ¡çŠ¶æ€

```powershell
docker compose ps
```

#### æŸ¥çœ‹æ—¥å¿—

```powershell
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker compose logs

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker compose logs airflow-apiserver
docker compose logs airflow-scheduler
```

#### é‡å¯æœåŠ¡

```powershell
docker compose restart
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
airflow/
â”œâ”€â”€ dags/              # å­˜æ”¾æ‚¨çš„ DAG æ–‡ä»¶ï¼ˆå·¥ä½œæµå®šä¹‰ï¼‰
â”œâ”€â”€ logs/              # Airflow æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ plugins/           # è‡ªå®šä¹‰æ’ä»¶
â”œâ”€â”€ config/            # é…ç½®æ–‡ä»¶
â”œâ”€â”€ .env               # ç¯å¢ƒå˜é‡
â””â”€â”€ docker-compose.yaml # Docker Compose é…ç½®
```

## ğŸ“ åˆ›å»ºæ‚¨çš„ç¬¬ä¸€ä¸ª DAG

åœ¨ `dags/` ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª Python æ–‡ä»¶ï¼Œä¾‹å¦‚ `my_first_dag.py`ï¼š

```python
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.bash import BashOperator

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2025, 11, 20),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'my_first_dag',
    default_args=default_args,
    description='æˆ‘çš„ç¬¬ä¸€ä¸ª DAG',
    schedule_interval=timedelta(days=1),
    catchup=False,
) as dag:

    task1 = BashOperator(
        task_id='print_hello',
        bash_command='echo "Hello from Airflow 3.1.3!"',
    )

    task2 = BashOperator(
        task_id='print_date',
        bash_command='date',
    )

    task1 >> task2  # task1 å®Œæˆåæ‰§è¡Œ task2
```

ä¿å­˜æ–‡ä»¶åï¼ŒAirflow ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶åŠ è½½æ–°çš„ DAGï¼ˆå¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰ã€‚

## ğŸ”§ è¿è¡Œä¸­çš„å®¹å™¨

å½“å‰è¿è¡Œçš„æœåŠ¡åŒ…æ‹¬ï¼š

- **airflow-apiserver**: Web UI å’Œ API æœåŠ¡å™¨ (ç«¯å£ 8080)
- **airflow-scheduler**: è°ƒåº¦å™¨ï¼Œè´Ÿè´£è°ƒåº¦ä»»åŠ¡
- **airflow-dag-processor**: DAG å¤„ç†å™¨
- **airflow-triggerer**: è§¦å‘å™¨ï¼Œå¤„ç†å»¶è¿Ÿä»»åŠ¡
- **airflow-worker**: Celery Workerï¼Œæ‰§è¡Œä»»åŠ¡ï¼ˆæŒ‰éœ€å¯åŠ¨ï¼‰
- **postgres**: PostgreSQL æ•°æ®åº“
- **redis**: Redis æ¶ˆæ¯é˜Ÿåˆ—

## ğŸ“š æ›´å¤šèµ„æº

- [Airflow å®˜æ–¹æ–‡æ¡£](https://airflow.apache.org/docs/apache-airflow/stable/)
- [Airflow æ•™ç¨‹](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/index.html)
- [DAG ç¼–å†™æŒ‡å—](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html)

## âš ï¸ æ³¨æ„äº‹é¡¹

1. è¿™æ˜¯å¼€å‘ç¯å¢ƒé…ç½®ï¼Œä¸å»ºè®®ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒ
2. é»˜è®¤ç”¨æˆ·åå’Œå¯†ç åº”è¯¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ›´æ”¹
3. DAG æ–‡ä»¶ä¼šè¢«è‡ªåŠ¨ç›‘æ§ï¼Œä¿®æ”¹åä¼šè‡ªåŠ¨é‡æ–°åŠ è½½
4. æ—¥å¿—æ–‡ä»¶ä¼šå­˜å‚¨åœ¨ `logs/` ç›®å½•ä¸‹

## ğŸ›‘ å®Œå…¨æ¸…ç†ï¼ˆå¦‚éœ€é‡æ–°å¼€å§‹ï¼‰

```powershell
# åœæ­¢å¹¶åˆ é™¤æ‰€æœ‰å®¹å™¨å’Œæ•°æ®å·
docker compose down -v

# æ¸…ç†æœ¬åœ°æ–‡ä»¶
Remove-Item -Recurse -Force logs/*
Remove-Item -Recurse -Force dags/*
Remove-Item -Recurse -Force plugins/*
Remove-Item -Recurse -Force config/*
```

---

**å®‰è£…æ—¥æœŸ**: 2025 å¹´ 11 æœˆ 20 æ—¥  
**Airflow ç‰ˆæœ¬**: 3.1.3  
**Python ç‰ˆæœ¬**: 3.12
